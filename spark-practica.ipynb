{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "sc =SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "url = \"https://github.com/guru99-edu/R-Programming/raw/master/adult_data.csv\"\n",
    "    \n",
    "sc.addFile(url)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.csv(SparkFiles.get(\"adult_data.csv\"), header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: integer (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: integer (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- capital-gain: integer (nullable = true)\n",
      " |-- capital-loss: integer (nullable = true)\n",
      " |-- hours-per-week: integer (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+---------------+\n",
      "|  x|age|fnlwgt|educational-num|\n",
      "+---+---+------+---------------+\n",
      "|  1| 25|226802|              7|\n",
      "|  2| 38| 89814|              9|\n",
      "|  3| 28|336951|             12|\n",
      "|  4| 44|160323|             10|\n",
      "|  5| 18|103497|             10|\n",
      "|  6| 34|198693|              6|\n",
      "|  7| 29|227026|              9|\n",
      "|  8| 63|104626|             15|\n",
      "|  9| 24|369667|             10|\n",
      "| 10| 55|104996|              4|\n",
      "| 11| 65|184454|              9|\n",
      "| 12| 36|212465|             13|\n",
      "| 13| 26| 82091|              9|\n",
      "| 14| 58|299831|              9|\n",
      "| 15| 48|279724|              9|\n",
      "| 16| 43|346189|             14|\n",
      "| 17| 20|444554|             10|\n",
      "| 18| 43|128354|              9|\n",
      "| 19| 37| 60548|              9|\n",
      "| 20| 40| 85019|             16|\n",
      "+---+---+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"x\", \"age\", \"fnlwgt\", \"educational-num\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "root\n",
      " |-- x: integer (nullable = true)\n",
      " |-- age: float (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: float (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: float (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- capital-gain: float (nullable = true)\n",
      " |-- capital-loss: float (nullable = true)\n",
      " |-- hours-per-week: float (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "def convertColumn(df, names, newType):\n",
    "    for name in names:\n",
    "        df = df.withColumn(name, df[name].cast(newType))\n",
    "    return df\n",
    "\n",
    "CONTI_FEATURES  = []\n",
    "\n",
    "for name, dtype in df.dtypes:\n",
    "    if dtype == \"int\" and not \"x\" in name:\n",
    "        CONTI_FEATURES.append(name)\n",
    "\n",
    "print(CONTI_FEATURES)\n",
    "\n",
    "df = convertColumn(df, CONTI_FEATURES, FloatType())\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|   education|count|\n",
      "+------------+-----+\n",
      "|   Preschool|   83|\n",
      "|     1st-4th|  247|\n",
      "|     5th-6th|  509|\n",
      "|   Doctorate|  594|\n",
      "|        12th|  657|\n",
      "|         9th|  756|\n",
      "| Prof-school|  834|\n",
      "|     7th-8th|  955|\n",
      "|        10th| 1389|\n",
      "|  Assoc-acdm| 1601|\n",
      "|        11th| 1812|\n",
      "|   Assoc-voc| 2061|\n",
      "|     Masters| 2657|\n",
      "|   Bachelors| 8025|\n",
      "|Some-college|10878|\n",
      "|     HS-grad|15784|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"education\").count().sort(\"count\", ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+-----------------+------------------+\n",
      "|summary|               age|            fnlwgt|   educational-num|      capital-gain|     capital-loss|    hours-per-week|\n",
      "+-------+------------------+------------------+------------------+------------------+-----------------+------------------+\n",
      "|  count|             48842|             48842|             48842|             48842|            48842|             48842|\n",
      "|   mean| 38.64358543876172|189664.13459727284|10.078088530363212|1079.0676262233324|87.50231358257237|40.422382375824085|\n",
      "| stddev|13.710509934443502|105604.02542315757| 2.570972755592252| 7452.019057655413|403.0045521243591|12.391444024252289|\n",
      "|    min|              17.0|           12285.0|               1.0|               0.0|              0.0|               1.0|\n",
      "|    max|              90.0|         1490400.0|              16.0|           99999.0|           4356.0|              99.0|\n",
      "+-------+------------------+------------------+------------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(CONTI_FEATURES).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----+\n",
      "|age_income|<=50K|>50K|\n",
      "+----------+-----+----+\n",
      "|      17.0|  595|   0|\n",
      "|      18.0|  862|   0|\n",
      "|      19.0| 1050|   3|\n",
      "|      20.0| 1112|   1|\n",
      "|      21.0| 1090|   6|\n",
      "|      22.0| 1161|  17|\n",
      "|      23.0| 1307|  22|\n",
      "|      24.0| 1162|  44|\n",
      "|      25.0| 1119|  76|\n",
      "|      26.0| 1068|  85|\n",
      "|      27.0| 1117| 115|\n",
      "|      28.0| 1101| 179|\n",
      "|      29.0| 1025| 198|\n",
      "|      30.0| 1031| 247|\n",
      "|      31.0| 1050| 275|\n",
      "|      32.0|  957| 296|\n",
      "|      33.0| 1045| 290|\n",
      "|      34.0|  949| 354|\n",
      "|      35.0|  997| 340|\n",
      "|      36.0|  948| 400|\n",
      "+----------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.crosstab(\"age\", \"income\").sort(\"age_income\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+----+\n",
      "|gender_income|<=50K|>50K|\n",
      "+-------------+-----+----+\n",
      "|       Female|14423|1769|\n",
      "|         Male|22732|9918|\n",
      "+-------------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.crosstab(\"gender\", \"income\").sort(\"gender_income\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x',\n",
       " 'age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'gender',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country',\n",
       " 'income']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('educational-num').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20211"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.age > 40).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|      marital-status| avg(capital-gain)|\n",
      "+--------------------+------------------+\n",
      "|           Separated| 581.8424836601307|\n",
      "|       Never-married|  384.382639449029|\n",
      "|Married-spouse-ab...| 629.0047770700637|\n",
      "|            Divorced| 793.6755615860094|\n",
      "|             Widowed| 603.6442687747035|\n",
      "|   Married-AF-spouse|2971.6216216216217|\n",
      "|  Married-civ-spouse|1739.7006121810625|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('marital-status').agg({'capital-gain': 'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: integer (nullable = true)\n",
      " |-- age: float (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: float (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: float (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- capital-gain: float (nullable = true)\n",
      " |-- capital-loss: float (nullable = true)\n",
      " |-- hours-per-week: float (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      " |-- age_square: double (nullable = true)\n",
      "\n",
      "+---+----+----------+\n",
      "|  x| age|age_square|\n",
      "+---+----+----------+\n",
      "|  1|25.0|     625.0|\n",
      "|  2|38.0|    1444.0|\n",
      "|  3|28.0|     784.0|\n",
      "|  4|44.0|    1936.0|\n",
      "|  5|18.0|     324.0|\n",
      "|  6|34.0|    1156.0|\n",
      "|  7|29.0|     841.0|\n",
      "|  8|63.0|    3969.0|\n",
      "|  9|24.0|     576.0|\n",
      "| 10|55.0|    3025.0|\n",
      "| 11|65.0|    4225.0|\n",
      "| 12|36.0|    1296.0|\n",
      "| 13|26.0|     676.0|\n",
      "| 14|58.0|    3364.0|\n",
      "| 15|48.0|    2304.0|\n",
      "| 16|43.0|    1849.0|\n",
      "| 17|20.0|     400.0|\n",
      "| 18|43.0|    1849.0|\n",
      "| 19|37.0|    1369.0|\n",
      "| 20|40.0|    1600.0|\n",
      "+---+----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df = df.withColumn(\"age_square\", col(\"age\")**2)\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "df.select(['x', 'age', 'age_square']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: integer (nullable = true)\n",
      " |-- age: float (nullable = true)\n",
      " |-- age_square: double (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: float (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: float (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- capital-gain: float (nullable = true)\n",
      " |-- capital-loss: float (nullable = true)\n",
      " |-- hours-per-week: float (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COLUMNAS = ['x',\n",
    "            'age',\n",
    "            'age_square',\n",
    "            'workclass',\n",
    "            'fnlwgt',\n",
    "            'education',\n",
    "            'educational-num',\n",
    "            'marital-status',\n",
    "            'occupation',\n",
    "            'relationship',\n",
    "            'race',\n",
    "            'gender',\n",
    "            'capital-gain',\n",
    "            'capital-loss',\n",
    "            'hours-per-week',\n",
    "            'native-country',\n",
    "            'income',\n",
    "            ]\n",
    "\n",
    "df = df.select(COLUMNAS)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|      native-country|count|\n",
      "+--------------------+-----+\n",
      "|  Holand-Netherlands|    1|\n",
      "|             Hungary|   19|\n",
      "|            Honduras|   20|\n",
      "|            Scotland|   21|\n",
      "|                Laos|   23|\n",
      "|          Yugoslavia|   23|\n",
      "|Outlying-US(Guam-...|   23|\n",
      "|     Trinadad&Tobago|   27|\n",
      "|            Cambodia|   28|\n",
      "|                Hong|   30|\n",
      "|            Thailand|   30|\n",
      "|             Ireland|   37|\n",
      "|              France|   38|\n",
      "|             Ecuador|   45|\n",
      "|                Peru|   46|\n",
      "|              Greece|   49|\n",
      "|           Nicaragua|   49|\n",
      "|                Iran|   59|\n",
      "|              Taiwan|   65|\n",
      "|            Portugal|   67|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('native-country').count().sort('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|      native-country|count|\n",
      "+--------------------+-----+\n",
      "|             Hungary|   19|\n",
      "|            Honduras|   20|\n",
      "|            Scotland|   21|\n",
      "|                Laos|   23|\n",
      "|          Yugoslavia|   23|\n",
      "|Outlying-US(Guam-...|   23|\n",
      "|     Trinadad&Tobago|   27|\n",
      "|            Cambodia|   28|\n",
      "|            Thailand|   30|\n",
      "|                Hong|   30|\n",
      "|             Ireland|   37|\n",
      "|              France|   38|\n",
      "|             Ecuador|   45|\n",
      "|                Peru|   46|\n",
      "|           Nicaragua|   49|\n",
      "|              Greece|   49|\n",
      "|                Iran|   59|\n",
      "|              Taiwan|   65|\n",
      "|            Portugal|   67|\n",
      "|               Haiti|   75|\n",
      "|            Columbia|   85|\n",
      "|             Vietnam|   86|\n",
      "|              Poland|   87|\n",
      "|           Guatemala|   88|\n",
      "|               Japan|   92|\n",
      "|  Dominican-Republic|  103|\n",
      "|               Italy|  105|\n",
      "|             Jamaica|  106|\n",
      "|               South|  115|\n",
      "|               China|  122|\n",
      "|             England|  127|\n",
      "|                Cuba|  138|\n",
      "|               India|  151|\n",
      "|         El-Salvador|  155|\n",
      "|              Canada|  182|\n",
      "|         Puerto-Rico|  184|\n",
      "|             Germany|  206|\n",
      "|         Philippines|  295|\n",
      "|                   ?|  857|\n",
      "|              Mexico|  951|\n",
      "|       United-States|43832|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_remove = df.filter(df['native-country'] != \"Holand-Netherlands\")\n",
    "\n",
    "df_remove.groupby('native-country').count().sort('count').show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Philippines\n",
      "Germany\n",
      "Cambodia\n",
      "France\n",
      "Greece\n",
      "Taiwan\n",
      "Ecuador\n",
      "Nicaragua\n",
      "Hong\n",
      "Peru\n",
      "India\n",
      "China\n",
      "Italy\n",
      "Holand-Netherlands\n",
      "Cuba\n",
      "South\n",
      "Iran\n",
      "Ireland\n",
      "Thailand\n",
      "Laos\n",
      "El-Salvador\n",
      "Mexico\n",
      "Guatemala\n",
      "Honduras\n",
      "Yugoslavia\n",
      "Puerto-Rico\n",
      "Jamaica\n",
      "Canada\n",
      "United-States\n",
      "Dominican-Republic\n",
      "Outlying-US(Guam-USVI-etc)\n",
      "Japan\n",
      "England\n",
      "Haiti\n",
      "Poland\n",
      "Portugal\n",
      "?\n",
      "Columbia\n",
      "Scotland\n",
      "Hungary\n",
      "Vietnam\n",
      "Trinadad&Tobago\n"
     ]
    }
   ],
   "source": [
    "paises = df.select('native-country').distinct().collect()\n",
    "\n",
    "for pais in paises:\n",
    "    print(pais['native-country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(native-country='Holand-Netherlands', count=1),\n",
       " Row(native-country='Hungary', count=19),\n",
       " Row(native-country='Honduras', count=20),\n",
       " Row(native-country='Scotland', count=21),\n",
       " Row(native-country='Laos', count=23),\n",
       " Row(native-country='Yugoslavia', count=23),\n",
       " Row(native-country='Outlying-US(Guam-USVI-etc)', count=23),\n",
       " Row(native-country='Trinadad&Tobago', count=27),\n",
       " Row(native-country='Cambodia', count=28),\n",
       " Row(native-country='Hong', count=30),\n",
       " Row(native-country='Thailand', count=30),\n",
       " Row(native-country='Ireland', count=37),\n",
       " Row(native-country='France', count=38),\n",
       " Row(native-country='Ecuador', count=45),\n",
       " Row(native-country='Peru', count=46),\n",
       " Row(native-country='Greece', count=49),\n",
       " Row(native-country='Nicaragua', count=49),\n",
       " Row(native-country='Iran', count=59),\n",
       " Row(native-country='Taiwan', count=65),\n",
       " Row(native-country='Portugal', count=67),\n",
       " Row(native-country='Haiti', count=75),\n",
       " Row(native-country='Columbia', count=85),\n",
       " Row(native-country='Vietnam', count=86),\n",
       " Row(native-country='Poland', count=87),\n",
       " Row(native-country='Guatemala', count=88),\n",
       " Row(native-country='Japan', count=92),\n",
       " Row(native-country='Dominican-Republic', count=103),\n",
       " Row(native-country='Italy', count=105),\n",
       " Row(native-country='Jamaica', count=106),\n",
       " Row(native-country='South', count=115),\n",
       " Row(native-country='China', count=122),\n",
       " Row(native-country='England', count=127),\n",
       " Row(native-country='Cuba', count=138),\n",
       " Row(native-country='India', count=151),\n",
       " Row(native-country='El-Salvador', count=155),\n",
       " Row(native-country='Canada', count=182),\n",
       " Row(native-country='Puerto-Rico', count=184),\n",
       " Row(native-country='Germany', count=206),\n",
       " Row(native-country='Philippines', count=295),\n",
       " Row(native-country='?', count=857),\n",
       " Row(native-country='Mexico', count=951),\n",
       " Row(native-country='United-States', count=43832)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = df.groupby('native-country').count().sort('count').collect()\n",
    "\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Holand-Netherlands \t 1\n",
      "                  Hungary \t 19\n",
      "                 Honduras \t 20\n",
      "                 Scotland \t 21\n",
      "                     Laos \t 23\n",
      "               Yugoslavia \t 23\n",
      "Outlying-US(Guam-USVI-etc) \t 23\n",
      "          Trinadad&Tobago \t 27\n",
      "                 Cambodia \t 28\n",
      "                     Hong \t 30\n",
      "                 Thailand \t 30\n",
      "                  Ireland \t 37\n",
      "                   France \t 38\n",
      "                  Ecuador \t 45\n",
      "                     Peru \t 46\n",
      "                   Greece \t 49\n",
      "                Nicaragua \t 49\n",
      "                     Iran \t 59\n",
      "                   Taiwan \t 65\n",
      "                 Portugal \t 67\n",
      "                    Haiti \t 75\n",
      "                 Columbia \t 85\n",
      "                  Vietnam \t 86\n",
      "                   Poland \t 87\n",
      "                Guatemala \t 88\n",
      "                    Japan \t 92\n",
      "       Dominican-Republic \t 103\n",
      "                    Italy \t 105\n",
      "                  Jamaica \t 106\n",
      "                    South \t 115\n",
      "                    China \t 122\n",
      "                  England \t 127\n",
      "                     Cuba \t 138\n",
      "                    India \t 151\n",
      "              El-Salvador \t 155\n",
      "                   Canada \t 182\n",
      "              Puerto-Rico \t 184\n",
      "                  Germany \t 206\n",
      "              Philippines \t 295\n",
      "                        ? \t 857\n",
      "                   Mexico \t 951\n",
      "            United-States \t 43832\n"
     ]
    }
   ],
   "source": [
    "for v in var:\n",
    "    print('{:>25} \\t {}'.format(v['native-country'], v['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "\n",
    "CATE_FEATURES  = []\n",
    "\n",
    "for name, dtype in df.dtypes:\n",
    "    if dtype == \"string\" and not \"income\" in name:\n",
    "        CATE_FEATURES.append(name)\n",
    "\n",
    "stages = []\n",
    "\n",
    "for categoricalCol in CATE_FEATURES:\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    encoder = OneHotEncoder(inputCols=[categoricalCol + \"Index\"], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelstringIdx = StringIndexer(inputCol=\"income\", outputCol=\"newlabel\")\n",
    "stages += [labelstringIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "assemblerInputs = [c + \"classVec\" for c in CATE_FEATURES] + CONTI_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol='features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline\n",
    "\n",
    "df_remove = df_remove.drop(\"x\")\n",
    "\n",
    "pipeline = Pipeline(stages=stages)\n",
    "pipelineModel = pipeline.fit(df_remove)\n",
    "model = pipelineModel.transform(df_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=25.0, age_square=625.0, workclass='Private', fnlwgt=226802.0, education='11th', educational-num=7.0, marital-status='Never-married', occupation='Machine-op-inspct', relationship='Own-child', race='Black', gender='Male', capital-gain=0.0, capital-loss=0.0, hours-per-week=40.0, native-country='United-States', income='<=50K', workclassIndex=0.0, workclassclassVec=SparseVector(8, {0: 1.0}), educationIndex=5.0, educationclassVec=SparseVector(15, {5: 1.0}), marital-statusIndex=1.0, marital-statusclassVec=SparseVector(6, {1: 1.0}), occupationIndex=6.0, occupationclassVec=SparseVector(14, {6: 1.0}), relationshipIndex=2.0, relationshipclassVec=SparseVector(5, {2: 1.0}), raceIndex=1.0, raceclassVec=SparseVector(4, {1: 1.0}), genderIndex=0.0, genderclassVec=SparseVector(1, {0: 1.0}), native-countryIndex=0.0, native-countryclassVec=SparseVector(40, {0: 1.0}), newlabel=0.0, features=SparseVector(99, {0: 1.0, 13: 1.0, 24: 1.0, 35: 1.0, 45: 1.0, 49: 1.0, 52: 1.0, 53: 1.0, 93: 25.0, 94: 226802.0, 95: 7.0, 98: 40.0}))]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import DenseVector\n",
    "\n",
    "input_data = model.rdd.map(lambda x: (x[\"newlabel\"], DenseVector(x[\"features\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = sqlContext.createDataFrame(input_data, [\"label\", \"features\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|[1.0,0.0,0.0,0.0,...|\n",
      "|  0.0|[1.0,0.0,0.0,0.0,...|\n",
      "|  1.0|[0.0,0.0,1.0,0.0,...|\n",
      "|  1.0|[1.0,0.0,0.0,0.0,...|\n",
      "|  0.0|[0.0,0.0,0.0,1.0,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df_train.randomSplit([.8, .2], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|29701|\n",
      "|  1.0| 9345|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.groupby(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 7453|\n",
      "|  1.0| 2342|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.groupby(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"label\",\n",
    "                       featuresCol=\"features\", \n",
    "                       maxIter=10,\n",
    "                       regParam=0.3)\n",
    "\n",
    "linearModel = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(linearModel.coefficients))\n",
    "print(\"Intercept: \" + str(linearModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluar modelo\n",
    "\n",
    "prediccions = linearModel.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediccions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|  0.0|       0.0|[0.93053780544176...|\n",
      "|  0.0|       0.0|[0.94603248831750...|\n",
      "|  0.0|       0.0|[0.81182553768189...|\n",
      "|  0.0|       0.0|[0.91346022215182...|\n",
      "|  0.0|       0.0|[0.55398815653954...|\n",
      "|  0.0|       1.0|[0.28877064190246...|\n",
      "|  0.0|       1.0|[0.35997365835694...|\n",
      "|  0.0|       0.0|[0.90778664876464...|\n",
      "|  0.0|       1.0|[0.44580363687604...|\n",
      "|  0.0|       1.0|[0.34448851921895...|\n",
      "|  0.0|       0.0|[0.89461993646948...|\n",
      "|  0.0|       0.0|[0.85109833395415...|\n",
      "|  0.0|       0.0|[0.84629201450027...|\n",
      "|  0.0|       0.0|[0.93049325351024...|\n",
      "|  0.0|       0.0|[0.66600206899818...|\n",
      "|  0.0|       0.0|[0.75939329677079...|\n",
      "|  0.0|       0.0|[0.83720480986057...|\n",
      "|  0.0|       0.0|[0.82666412168648...|\n",
      "|  0.0|       0.0|[0.80823811902389...|\n",
      "|  0.0|       0.0|[0.84657848922666...|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected = prediccions.select(\"label\", \"prediction\", \"probability\")\n",
    "selected.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8250127616130679"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = selected.select([\"label\", \"prediction\"])\n",
    "cm.filter(cm.label == cm.prediction).count() / cm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate 0.8893672766071866\n",
      "MetricName areaUnderROC\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print(\"evaluate\", evaluator.evaluate(prediccions))\n",
    "print(\"MetricName\", evaluator.getMetricName())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "            .addGrid(lr.regParam, [0.01, 0.5])\n",
    "            .build())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import *\n",
    "start_time = time()\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(train_data)\n",
    "\n",
    "# likely take a fair amount of time\n",
    "end_time = time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Time to train model: %.3f seconds\" % elapsed_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
